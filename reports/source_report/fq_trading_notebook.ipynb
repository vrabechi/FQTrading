{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Financial Time Series\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The objective of this project is to develop a deep learning model that predicts positive trends in Bitcoin prices. This project focuses on utilizing Long Short-Term Memory (LSTM), a type of recurrent neural network, to analyze and forecast time series data, aiming to accurately identify potential upward movements in the cryptocurrency market and provide insights into future price movements. The model is trained using historical Bitcoin data and evaluated through backtesting with a binary classification approach.\n",
    "#\n",
    "## Introduction\n",
    "\n",
    "### Background\n",
    "\n",
    "The financial markets, especially cryptocurrency markets, are known for their volatility and complex dynamics. Predicting the price movements of cryptocurrencies like Bitcoin is a challenging task due to the high noise-to-signal ratio. Traditional statistical methods often fall short in capturing the nonlinear and temporal dependencies in such data.\n",
    "\n",
    "### Literature Review\n",
    "\n",
    "#### Previous Works\n",
    "\n",
    "Various machine learning and deep learning techniques have been employed for stock and cryptocurrency price predictions, each offering unique strengths and weaknesses. This section provides an overview of these methods and highlights significant previous works.\n",
    "\n",
    "#### Artificial Neural Network (ANN)\n",
    "\n",
    "- Artificial Neural Networks have been one of the earliest deep learning approaches used for financial market predictions. They consist of multiple layers of interconnected neurons that process input features to make predictions. ANNs can model complex nonlinear relationships, making them suitable for predicting market prices.\n",
    "- **Kimoto et al. (1990)** used a neural network to predict stock prices on the Tokyo Stock Exchange. Their model incorporated technical indicators as input features and achieved notable predictive accuracy.\n",
    "- **Challenges**: ANNs often struggle with temporal dependencies in time series data, leading to the development of more specialized architectures like RNNs and LSTMs.\n",
    "\n",
    "#### Support Vector Machine (SVM)\n",
    "\n",
    "- Support Vector Machines are a type of supervised learning algorithm that can be used for classification and regression tasks. SVMs work by finding the optimal hyperplane that separates data points of different classes with the maximum margin.\n",
    "- **Kim (2003)** applied SVMs to predict the direction of stock price movements based on technical indicators. The study demonstrated that SVMs could outperform traditional linear models.\n",
    "- **Challenges**: SVMs can be computationally expensive and may require significant tuning of hyperparameters. They also struggle with large and complex datasets.\n",
    "\n",
    "#### Recurrent Neural Network (RNN)\n",
    "\n",
    "- Recurrent Neural Networks are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps. RNNs can model temporal dependencies, making them suitable for time series forecasting.\n",
    "- **Chong et al. (2017)** used RNNs to predict stock prices and found that RNNs could effectively capture temporal patterns in financial data. Their study showed improved performance compared to traditional methods.\n",
    "- **Challenges**: RNNs suffer from vanishing and exploding gradient problems, which can hinder their ability to learn long-term dependencies.\n",
    "\n",
    "#### Long Short-Term Memory Network (LSTM)\n",
    "\n",
    "- Long Short-Term Memory networks are a specialized type of RNN designed to address the limitations of traditional RNNs. LSTMs use gating mechanisms to control the flow of information, allowing them to retain long-term dependencies and mitigate the vanishing gradient problem.\n",
    "- **Fischer and Krauss (2018)** employed LSTMs to predict stock returns based on historical price data. Their model outperformed benchmark models, demonstrating the effectiveness of LSTMs in financial time series forecasting.\n",
    "- **McNally et al. (2018)** applied LSTMs to predict Bitcoin prices. They compared LSTM performance with ARIMA and SVM models, concluding that LSTMs provided superior predictive accuracy for cryptocurrency prices.\n",
    "- **Advantages**: LSTMs are highly effective at capturing complex temporal patterns and long-term dependencies, making them well-suited for financial market predictions.\n",
    "\n",
    "#### Convolutional Neural Network (CNN)\n",
    "\n",
    "- Convolutional Neural Networks, typically used for image processing tasks, have also been adapted for time series forecasting. By treating time series data as one-dimensional images, CNNs can capture local patterns and trends.\n",
    "- **Borovykh et al. (2017)** explored the use of CNNs for financial time series forecasting. Their study showed that CNNs could capture local dependencies and provided competitive performance compared to RNNs.\n",
    "- **Challenges**: CNNs may not be as effective as LSTMs in capturing long-term dependencies but can be useful for identifying local patterns in data.\n",
    "\n",
    "#### Hybrid Models\n",
    "\n",
    "- Hybrid models combine different machine learning techniques to leverage their individual strengths. For example, combining CNNs and LSTMs can capture both local and long-term dependencies in time series data.\n",
    "- **Wang et al. (2020)** developed a hybrid model combining CNNs and LSTMs for stock price prediction. Their approach achieved improved predictive performance by leveraging the strengths of both architectures.\n",
    "\n",
    "LSTM networks have been widely used for financial time series prediction due to their capability to handle sequential data. Studies have demonstrated their effectiveness in predicting stock prices, index trends, and even cryptocurrency prices. The integration of LSTM with robust feature engineering techniques has shown significant improvements in prediction accuracy.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "The goal is to predict whether the Bitcoin price will increase or decrease in the next time period based on historical data. The problem is framed as a binary classification task where the target variable indicates a price increase (1) or decrease (0).\n",
    "\n",
    "**Long Short-Term Memory (LSTM)** networks are capable of learning long-term dependencies in data sequences. They are particularly effective for applications such as time series prediction due to their structure, which allows them to remember information for long periods. This is critical in financial markets where past price actions can influence future trends.\n",
    "\n",
    "#### Application to Bitcoin Price Prediction\n",
    "\n",
    "For predicting Bitcoin prices, we utilize an LSTM in a `many-to-one` configuration, where multiple past data features are used to predict a binary outcome indicating whether the price will close up or down in the next time period. This binary classification approach aims to capture the inherently noisy and non-linear patterns of price movements in the cryptocurrency market.\n",
    "\n",
    "In this project, 8 years of daily Bitcoin data sourced from the Yahoo Finance API were used. The approach involves constructing and fine-tuning a stacked LSTM network, tailored to work with a sequence length of 15. This specific sequence length is chosen to capture relevant temporal patterns in the Bitcoin market, allowing for a more informed and accurate prediction of trend movements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas_ta as ta\n",
    "from pathlib import Path\n",
    "from scipy.stats import f_oneway\n",
    "import yfinance as yf\n",
    "import pyfolio as pf\n",
    "\n",
    "# Import Boruta for feature selection\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting and visualization\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = 10, 4\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, recall_score, precision_score,precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix, plot_confusion_matrix,balanced_accuracy_score,\n",
    "    auc, roc_curve, plot_roc_curve, roc_auc_score,ConfusionMatrixDisplay\n",
    "    )\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Accuracy, AUC, Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Callback\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, LSTM, BatchNormalization, GRU, Conv1D, MaxPooling1D\n",
    "\n",
    "# Optuna for hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.integration import TensorBoardCallback\n",
    "import optuna.visualization as vis\n",
    "\n",
    "# Sweetviz for EDA\n",
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed\n",
    "def set_seeds(seed=42): \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is TensorFlow visualization toolkit, enabling to track metrics like loss and accuracy, visualize the model graph, view histograms of weights, biases, or other tensors as they change over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get data\n",
    "def getdata(df):\n",
    "    # Ensure datetime is the index and convert it if necessary\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if 'Datetime' in df.columns:\n",
    "            df.set_index('Datetime', drop=True, inplace=True)\n",
    "        else:\n",
    "            print(\"No Datetime column found.\")\n",
    "            return None\n",
    "    df['Day'] = df.index.day_name()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Download data\n",
    "df = yf.download(tickers=\"BTC-USD\", period=\"96mo\")\n",
    "df = getdata(df)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of the Week Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DayTransformer is a custom transformer class designed for feature engineering with time series data. It takes a dataframe with datetime information and adds two new features: `dsin` and `dcos`. These features are derived from the day of the week, encoded as sine and cosine values to capture the cyclical nature of days in a week. This approach helps preserve the cyclical continuity (e.g., the closeness between Sunday and Monday) which is often important in time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for days\n",
    "class DayTransformer(BaseEstimator, TransformerMixin):                                  \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "            self.data = pd.DataFrame(\n",
    "                {\n",
    "            'WeekDay': [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "                }\n",
    "            )\n",
    "            self.daysnum = np.array(self.data.index+1)\n",
    "            return self\n",
    "        \n",
    "    def transform(self, X):  \n",
    "        Xt = X.copy()\n",
    "        pi = np.pi\n",
    "        num = Xt.index.weekday + 1\n",
    "        Xt['dsin'] = np.sin(2 * pi * num / np.max(self.daysnum))\n",
    "        Xt['dcos'] = np.cos(2 * pi * num / np.max(self.daysnum))\n",
    "        Xt = Xt.drop(['Day'], axis=1)\n",
    "        return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day transformer\n",
    "dtrans= DayTransformer()\n",
    "\n",
    "# fit\n",
    "dtrans.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dtrans.transform(df)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use df.columns to dynamically get all column names\n",
    "columns = df.columns\n",
    "\n",
    "# Plot 3 box plots per row\n",
    "for i in range(0, len(columns), 3):\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    for j, ax in enumerate(axes):\n",
    "        if i + j < len(columns):\n",
    "            sns.boxplot(x=df[columns[i + j]], ax=ax)\n",
    "            ax.set_title(f'Box Plot of {columns[i + j]}')\n",
    "        else:\n",
    "            ax.axis('off')  # Hide the unused subplot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots\n",
    "sns.pairplot(df)\n",
    "plt.suptitle('Pair Plot of All Features',y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Expansion\n",
    "\n",
    "To enhance the predictive power of the model, we incorporated a variety of features designed to capture the temporal dependencies inherent in financial time series data.\n",
    "\n",
    "#### Technical Indicators\n",
    "\n",
    "In the initial phase, we leveraged a comprehensive set of technical indicators to assess market conditions and trends. Utilizing the `pandas-ta` library, which offers over 100 technical indicators, we were able to capture a wide array of market signals. These indicators included various types of moving averages, momentum oscillators like the Relative Strength Index (RSI), and volatility measures such as Bollinger Bands, among others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add all factors\n",
    "df.ta.strategy('All')\n",
    "df = df.bfill(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagged Features\n",
    "\n",
    "We introduced lagged versions of return and applied binary transformations to potentially capture temporal dependencies and patterns in the data, utilizing lagged features alongside additional feature engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "df['Return'] = df['Close'].pct_change().fillna(0)\n",
    "\n",
    "# Statistical summary\n",
    "df['Return'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute lagged returns\n",
    "cols = []\n",
    "for lag in [1, 2, 3, 4, 5]:\n",
    "    col = f'Return_{lag}'\n",
    "    df[col] = df.Return.shift(lag)  \n",
    "    cols.append(col)\n",
    "\n",
    "# Drop NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Binary transformation\n",
    "cols_bin = []\n",
    "for col in cols:\n",
    "    col_bin = f'{col}_bin'\n",
    "    df[col_bin] = np.digitize(df[col], bins=[0])\n",
    "    cols_bin.append(col_bin)\n",
    "\n",
    "# Add other features\n",
    "df['o2c'] = df['Open'] - df['Close']\n",
    "df['h2l'] = df['High'] - df['Low']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(['Return_1', 'Return_2', 'Return_3', 'Return_4', 'Return_5'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label or the target variable is also known as the dependent variable. Here, the target variable is wether Bitcoin prices will close up or down on the next day.\n",
    "\n",
    "Class Labeling: The target variable $\\hat{y}_t$ is defined as:\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = \n",
    "\\begin{cases} \n",
    "1 & \\text{if } P_{t+1} > 0.995 \\times P_t \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $P_t$ is the current day adjusted closing price, and $P_{t+1}$ is the next day adjusted closing price.\n",
    "\n",
    "A specific threshold is set to categorize price movements. The threshold of 0.995 times the current day price is used to filter out very small, near-zero returns. By setting a specific percentage increase as the criterion for a signal, the model aims to avoid reacting to minor fluctuations, which are common in volatile markets like cryptocurrencies. This threshold helps in reducing noise in the prediction model, focusing on more substantial and potentially profitable price movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold\n",
    "df['dir'] = np.where(df['Adj Close'].shift(-1)>0.995*df['Adj Close'],1,0)\n",
    "\n",
    "# Specify target\n",
    "y = df['dir'].values\n",
    "\n",
    "# Pandas-ta converts all dtype to objects\n",
    "y = y.astype(int) \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "X = df.drop('dir', axis=1)\n",
    "feature_names = X.columns\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dates from the DataFrame for future reference\n",
    "dates = df.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class imbalance is a common issue in machine learning, particularly in classification problems where the number of instances in each class is not evenly distributed. This can lead to biased models that perform well on the majority class but poorly on the minority class, as the model tends to predict the majority class more frequently due to its higher occurrence in the training data.\n",
    "\n",
    "To mitigate this issue, several techniques can be applied, such as resampling the dataset, using different evaluation metrics, or adjusting class weights. In this work, we addressed class imbalance by computing class weights that are inversely proportional to the class frequencies. This approach ensures that the model pays equal attention to both classes, thus improving its ability to generalize. This way we can build a more robust and unbiased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute class weights\n",
    "def cwts(dfs):\n",
    "    c0, c1 = np.bincount(dfs['dir'])\n",
    "    w0 = (1 / c0) * (len(dfs) / 2)\n",
    "    w1 = (1 / c1) * (len(dfs) / 2)\n",
    "    return {0: w0, 1: w1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class frequency\n",
    "c = np.bincount(y)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class weights\n",
    "class_weight = cwts(df)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the calculated weights, both classes gain equal weight\n",
    "class_weight[0] * c[0], class_weight[1] * c[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test  Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Split training into training and validation\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.25, shuffle=False) \n",
    "\n",
    "# Convert to arrays\n",
    "Xtrain, Xval, Xtest, ytrain, yval, ytest = map(np.array, [Xtrain, Xval, Xtest, ytrain, yval, ytest])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "The feature selection in this model leverages multiple methods, each adding a layer of sophistication to how features are selected and evaluated:\n",
    "\n",
    "1. **Boruta Algorithm**:\n",
    "   Boruta is an all-relevant feature selection method, particularly effective in distinguishing between relevant and irrelevant features by employing a statistical test. It operates by creating shadow features (random shuffles of real features) and iteratively compares the importance of actual features with these shadows as determined by a Random Forest classifier. The importance measure used is the Mean Decrease in Impurity (MDI) of the Random Forest, calculated as follows:\n",
    "\n",
    "   $$\n",
    "   \\text{Importance}(X_i) = \\sum_{t \\in T : v(s_t) = X_i} p(t) \\cdot \\Delta i(s_t, t)\n",
    "   $$\n",
    "\n",
    "   Where:\n",
    "   - $X_i$ is a feature.\n",
    "   - $T$ represents all trees in the Random Forest.\n",
    "   - $s_t$ is the split involving $X_i$ in tree $t$.\n",
    "   - $p(t)$ is the proportion of samples reaching $s_t$.\n",
    "   - $\\Delta i(s_t, t)$ is the impurity decrease from the split $s_t$.\n",
    "\n",
    "   The iterative process continues until all features are classified as significant or not, with a max iteration parameter `max_iter` controlling the number of runs.\n",
    "#\n",
    "\n",
    "2. **Correlation Analysis**:\n",
    "    To address multicollinearity, we perform correlation analysis among the features. Highly correlated features are identified, and one feature from each pair is removed. The Pearson correlation coefficient is used, calculated as:\n",
    "\n",
    "    $$ \\rho_{X,Y} = \\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "   Where:\n",
    "   - $\\text{cov}(X,Y)$ is the covariance of features $X$ and $Y$.\n",
    "   - $\\sigma_X$ and $\\sigma_Y$ are the standard deviations of $X$ and $Y$ respectively.\n",
    "\n",
    " #  \n",
    "3. **Mutual Information (MI)**:\n",
    "   MI is used as a filter method to evaluate the dependency of each feature on the target variable. Unlike linear correlation measures, Mutual Information quantifies the amount of information obtained about one variable through another, capturing both linear and nonlinear relationships. It is particularly valuable in complex datasets where linear correlations may not adequately describe the interactions between features and the target. The Mutual Information between two variables $X$ and $Y$ is defined as:\n",
    "\n",
    "   $$\n",
    "   MI(X;Y) = \\sum_{x \\in X, y \\in Y} p(x, y) \\log \\frac{p(x, y)}{p(x) p(y)}\n",
    "   $$\n",
    "\n",
    "   Where:\n",
    "   - $p(x, y)$ is the joint probability distribution function of $X$ and $Y$.\n",
    "   - $p(x)$ and $p(y)$ are the marginal probability distribution functions of $X$ and $Y$ respectively.\n",
    "   #\n",
    "4. **K-Means Clustering**\n",
    "K-Means is employed for dimensionality reduction and to handle non-linearity by examining feature behavior across different clusters. The centroids found by K-Means can hint at natural groupings in data, which could potentially reveal patterns beneficial for prediction. The optimization goal of K-Means is to minimize the within-cluster sum of squares (WCSS), represented as:\n",
    "\n",
    "$$ \\text{WCSS} = \\sum_{i=1}^{k} \\sum_{x \\in C_i} \\|x - \\mu_i\\|^2 $$\n",
    "\n",
    "Where:\n",
    "- $C_i$ is the set of points in cluster $i$.\n",
    "- $\\mu_i$ is the centroid of cluster $i$.\n",
    "- $k$ is the number of clusters.\n",
    "\n",
    "By combining these methods, the selection process becomes more comprehensive, leading to a more refined and effective feature set for training the deep learning model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Borutapy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boruta iteratively removes features that are deemed less important, and its process continues until they are either confirmed or rejected as significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random forest classifier\n",
    "forest = RandomForestClassifier(n_jobs=-1, \n",
    "                                class_weight=cwts(df), \n",
    "                                random_state=42, \n",
    "                                max_depth=10)\n",
    "\n",
    "# Train the model\n",
    "forest.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Boruta feature selection method\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', perc=10, alpha=0.05, random_state=42, max_iter=100, verbose=2)\n",
    "\n",
    "# Find all relevant features\n",
    "feat_selector.fit(Xtrain, ytrain) \n",
    "\n",
    "# Call transform() on X to filter it down to selected features\n",
    "Xtrain = feat_selector.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip names, ranks, and decisions in a single iterable\n",
    "feature_ranks = list(zip(feature_names, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# Iterate through and print out the results\n",
    "for feat in feature_ranks:\n",
    "    print(f'Feature: {feat[0]:<30} Rank: {feat[1]:<5} Keep: {feat[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the feature names based on Boruta selection\n",
    "selected_feature_names = [name for name, selected in zip(feature_names, feat_selector.support_) if selected]\n",
    "\n",
    "# Create a DataFrame with only the selected features\n",
    "selected_features_df = df[selected_feature_names]\n",
    "selected_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Boruta transformation to Xtest and Xval\n",
    "Xtest = feat_selector.transform(np.array(Xtest))\n",
    "Xval = feat_selector.transform(np.array(Xval))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify correlated features\n",
    "def correlated_features(df, threshold=0.9):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = df.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: \n",
    "                colname = corr_matrix.columns[i]  # getting the name of the column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "# Identify correlated features in the selected features DataFrame\n",
    "correlated = correlated_features(selected_features_df)\n",
    "print(f\"Correlated features to be removed: {correlated}\")\n",
    "\n",
    "# Ensure all datasets (Xtrain, Xtest, Xval) are aligned with selected feature names\n",
    "Xtrain_df = pd.DataFrame(Xtrain, columns=selected_feature_names)\n",
    "Xtest_df = pd.DataFrame(Xtest, columns=selected_feature_names)\n",
    "Xval_df = pd.DataFrame(Xval, columns=selected_feature_names)\n",
    "\n",
    "# Drop correlated features from Xtrain, Xtest, and Xval\n",
    "Xtrain_df.drop(columns=correlated, inplace=True)\n",
    "Xtest_df.drop(columns=correlated, inplace=True)\n",
    "Xval_df.drop(columns=correlated, inplace=True)\n",
    "\n",
    "# Convert back to NumPy arrays\n",
    "Xtrain = Xtrain_df.values\n",
    "Xtest = Xtest_df.values\n",
    "Xval = Xval_df.values\n",
    "\n",
    "# Print the new shapes of the datasets\n",
    "print(f\"Xtrain shape after dropping correlated features: {Xtrain.shape}\")\n",
    "print(f\"Xtest shape after dropping correlated features: {Xtest.shape}\")\n",
    "print(f\"Xval shape after dropping correlated features: {Xval.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the updated list of feature names after removing correlated features\n",
    "updated_feature_names = Xtrain_df.columns.tolist()\n",
    "\n",
    "# Convert the numpy arrays to DataFrames with updated feature names\n",
    "Xtrain_df = pd.DataFrame(Xtrain, columns=updated_feature_names)\n",
    "Xval_df = pd.DataFrame(Xval, columns=updated_feature_names)\n",
    "Xtest_df = pd.DataFrame(Xtest, columns=updated_feature_names)\n",
    "\n",
    "# Calculate Mutual Information for each feature\n",
    "mi = mutual_info_classif(Xtrain_df, ytrain)\n",
    "\n",
    "# Create a DataFrame for Mutual Information\n",
    "mi_data = pd.DataFrame({'feature': updated_feature_names, 'mutual_info': mi})\n",
    "\n",
    "# Sort features by their mutual information\n",
    "mi_data = mi_data.sort_values(by='mutual_info', ascending=False)\n",
    "\n",
    "# Display the sorted mutual information\n",
    "mi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_data = mi_data.sort_values(by='mutual_info', ascending=True)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(mi_data['feature'], mi_data['mutual_info'], color='skyblue')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Mutual Information Scores Per Feature')\n",
    "\n",
    "# Draw a line for the threshold\n",
    "plt.axvline(x=0.001, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for mutual information\n",
    "mi_threshold = 0.001  \n",
    "\n",
    "# Identify features to drop based on mutual information threshold\n",
    "features_to_drop_mi = mi_data[mi_data['mutual_info'] < mi_threshold]['feature'].tolist()\n",
    "\n",
    "# Drop features from the training data based on mutual information\n",
    "Xtrain_df.drop(columns=features_to_drop_mi, inplace=True)\n",
    "\n",
    "# Drop Mutual Information filtered columns from validation and test sets\n",
    "Xval_df.drop(columns=features_to_drop_mi, inplace=True)\n",
    "Xtest_df.drop(columns=features_to_drop_mi, inplace=True)\n",
    "\n",
    "# Convert back to NumPy arrays\n",
    "Xtrain = Xtrain_df.values\n",
    "Xtest = Xtest_df.values\n",
    "Xval = Xval_df.values\n",
    "\n",
    "# Print the new shapes of the datasets\n",
    "print(f\"Xtrain shape after dropping MI features: {Xtrain.shape}\")\n",
    "print(f\"Xtest shape after dropping MI features: {Xtest.shape}\")\n",
    "print(f\"Xval shape after dropping MI features: {Xval.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters\n",
    "num_clusters = 35\n",
    "\n",
    "# Initialize KMeans\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)   \n",
    "\n",
    "# Fit KMeans to the training data\n",
    "kmeans.fit(Xtrain)\n",
    "\n",
    "# Transform the datasets based on the cluster assignments\n",
    "Xtrain = kmeans.transform(Xtrain)\n",
    "Xtest = kmeans.transform(Xtest)\n",
    "Xval = kmeans.transform(Xval)\n",
    "\n",
    "# Print the new shapes of the datasets\n",
    "print(f\"Xtrain shape after KMeans transformation: {Xtrain.shape}\")\n",
    "print(f\"Xtest shape after KMeans transformation: {Xtest.shape}\")\n",
    "print(f\"Xval shape after KMeans transformation: {Xval.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final EDA after Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for the transformed Xtrain\n",
    "df_Xtrain = pd.DataFrame(Xtrain, columns=[f'feature_{i}' for i in range(num_clusters)])\n",
    "\n",
    "# Statistical summary\n",
    "df_Xtrain.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Sweetviz report\n",
    "report = sv.analyze(df_Xtrain)\n",
    "\n",
    "# Save the report to an HTML file\n",
    "report.show_html('df_Xtrain_sweetviz_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon conducting Exploratory Data Analysis on the dataset, we observed significant variability and the presence of outliers in the feature distributions, as evidenced by high standard deviations and wide ranges in the summary statistics. Given these characteristics, the most appropriate transformation to standardize the data is the RobustScaler.\n",
    "\n",
    "Unlike the StandardScaler, which is sensitive to outliers, and the MinMaxScaler, which scales data to a fixed range but can be distorted by outliers, the RobustScaler scales the data using the interquartile range (IQR). This method is particularly effective for datasets with outliers, as it focuses on the central 50% of the data, thereby minimizing the influence of extreme values and ensuring a more robust standardization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "scaledtrain = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Transform the test data\n",
    "scaledtest = scaler.transform(Xtest)\n",
    "\n",
    "# Transform the validation data\n",
    "scaledval = scaler.transform(Xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Data Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `many-to-one` sequence problem, the input of the LSTM is always a 3D array and the time series data must be transformed into a structure of samples with input and output components before it can be used to fit a supervised learning model.\n",
    "\n",
    "The Keras deep learning library provides the TimeseriesGenerator to automatically transform both univariate and multivariate time series data into samples, ready to train deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length\n",
    "seqlen = 15\n",
    "\n",
    "# Number of features\n",
    "numfeat = Xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator for training data\n",
    "g_train = TimeseriesGenerator(Xtrain, ytrain, length=seqlen, batch_size=32)  \n",
    "\n",
    "# Create the generator for test data\n",
    "g_test = TimeseriesGenerator(Xtest, ytest, length=seqlen, batch_size=32)\n",
    "\n",
    "# Create the generator for validation data\n",
    "g_val = TimeseriesGenerator(Xval, yval, length=seqlen, batch_size=32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify length\n",
    "len(g_train), len(g_test), len(g_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature set\n",
    "g_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target \n",
    "g_train[0][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify batch size\n",
    "for i in range(len(g_train)):\n",
    "    a, b = g_train[i]\n",
    "    print(a.shape, b.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we experimented with five different model architectures to predict the target variable. The models include variations in LSTM configurations, the use of GRU, and the incorporation of convolutional layers. Here are the detailed descriptions of each model:\n",
    "\n",
    "#### Model 1: 2-Layer LSTM\n",
    "\n",
    "This model consists of 2 LSTM layers interspersed with a dropout layer. The first LSTM layer returns sequences, and the second LSTM layer returns the final output.\n",
    "\n",
    "The core idea behind LSTMs is the cell state, which acts like a conveyor belt transporting information down the sequence chain with minimal changes. The information flow is regulated by structures called gates:\n",
    "\n",
    "1. **Forget Gate**: Decides what information should be discarded from the cell state. It looks at the previous hidden state $h_{t-1}$ and the current input $x_t$, and outputs a number between 0 and 1 for each number in the cell state $C_{t-1}$. The forget gate operation is formulated as:\n",
    "   $$\n",
    "   f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n",
    "   $$\n",
    "   where $\\sigma$ is the sigmoid function, $W_f$ is the weight matrix for the forget gate, and $b_f$ is the bias.\n",
    "\n",
    "2. **Input Gate**: Decides which new information to store in the cell state. It involves a sigmoid layer that decides which values to update, and a tanh layer that creates a vector of new candidate values, $\\tilde{C}_t$, that could be added to the state:\n",
    "   $$\n",
    "   i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n",
    "   $$\n",
    "   $$\n",
    "   \\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\n",
    "   $$\n",
    "\n",
    "3. **Output Gate**: Determines the next hidden state, which contains information about the previous input. The hidden state can be used in predictions:\n",
    "   $$\n",
    "   o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n",
    "   $$\n",
    "   $$\n",
    "   h_t = o_t * \\tanh(C_t)\n",
    "   $$\n",
    "#\n",
    "#### Model 2: 3-Layer LSTM\n",
    "\n",
    "This model extends Model 1 by adding an additional LSTM layer and another dropout layer. The extra LSTM layer is used to capture more complex temporal patterns in the data.\n",
    "#\n",
    "#### Model 3: 4-Layer LSTM \n",
    "\n",
    "This model builds on Model 2 by using ELU activation functions for all LSTM layers and adding another LSTM and dropout layer. The ELU (Exponential Linear Unit) activation function is defined as:\n",
    "  $$\n",
    "  \\text{ELU}(x) = \\begin{cases} \n",
    "  x & \\text{if } x \\geq 0 \\\\\n",
    "  \\alpha(e^x - 1) & \\text{if } x < 0 \n",
    "  \\end{cases}\n",
    "  $$\n",
    "  where $\\alpha$ is a hyperparameter.\n",
    "\n",
    "- ELU helps to mitigate the vanishing gradient problem, which can lead to better learning in deeper networks by providing non-zero gradients for negative values.\n",
    "\n",
    "#### Model 4: 3-Layer GRU \n",
    "\n",
    "This model replaces LSTM layers with GRU (Gated Recurrent Unit) layers. GRUs simplify the LSTM architecture by combining the forget and input gates into a single update gate. The GRU cell can be described by the following equations:\n",
    "  $$\n",
    "  \\begin{align*}\n",
    "  z_t &= \\sigma(W_z \\cdot [h_{t-1}, x_t] + b_z) \\\\\n",
    "  r_t &= \\sigma(W_r \\cdot [h_{t-1}, x_t] + b_r) \\\\\n",
    "  \\tilde{h}_t &= \\tanh(W_h \\cdot [r_t \\cdot h_{t-1}, x_t] + b_h) \\\\\n",
    "  h_t &= (1 - z_t) \\cdot h_{t-1} + z_t \\cdot \\tilde{h}_t\n",
    "  \\end{align*}\n",
    "  $$\n",
    "  where $z_t$ is the update gate, $r_t$ is the reset gate, and $h_t$ is the hidden state.\n",
    "\n",
    "- **GRU Layer**: GRU layers are used to capture temporal dependencies in the data, simplifying the architecture and often training faster than LSTMs while providing similar performance.\n",
    "\n",
    "#### Model 5: Convolutional Layer Followed by LSTM\n",
    "\n",
    "This model incorporates a 1D convolutional layer before the LSTM layer. The convolutional layer helps in extracting local features from the input time series data. The combination of CNN and LSTM allows the model to leverage both spatial (local feature) and temporal (sequence dependency) information. \n",
    "\n",
    "##### Convolutional Layer (Conv1D)\n",
    "The Conv1D layer is used to extract local patterns and features from the input time series data. The operation can be described as:\n",
    "  $$\n",
    "  y(t) = (x * w)(t) = \\sum_{a} x(a) \\cdot w(t - a)\n",
    "  $$\n",
    "  where $*$ denotes the convolution operation, $x$ is the input signal, and $w$ is the filter (kernel).\n",
    "\n",
    "Key components of the Conv1D layer:\n",
    "- **Filters/Kernels**: Small matrices that slide over the input data to detect patterns.\n",
    "- **Stride**: The number of steps the filter moves over the input data. \n",
    "- **Padding**: Controls the handling of borders.\n",
    "\n",
    "The convolution operation is followed by a non-linear activation function, typically ReLU (Rectified Linear Unit):\n",
    "  $$\n",
    "  \\text{ReLU}(z) = \\max(0, z)\n",
    "  $$\n",
    "\n",
    "##### LSTM Layer\n",
    "After the Conv1D layer, the extracted features are fed into an LSTM to capture temporal dependencies. \n",
    "\n",
    "Potential advantages of combining Conv1D and LSTM:\n",
    "1. **Feature Extraction**: The Conv1D layer extracts local features and patterns from raw input data.\n",
    "2. **Sequence Learning**: The LSTM layer captures temporal dependencies and patterns in the sequence of extracted features.\n",
    "#\n",
    "#### Model Compilation\n",
    "\n",
    "- **Optimizer**: The Adam optimizer is used for training, which is an algorithm for first-order gradient-based optimization of stochastic objective functions. It combines the advantages of two other extensions of stochastic gradient descent: Adaptive Gradient Algorithm (AdaGrad) and Root Mean Square Propagation (RMSProp).\n",
    "  $$\n",
    "  \\text{Adam}(g, m, v, t) = \\frac{\\alpha \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "  $$\n",
    "  where $g$ is the gradient, $m$ is the first moment (mean of the gradients), $v$ is the second moment (uncentered variance of the gradients), $\\alpha$ is the learning rate, $\\epsilon$ is a small constant to prevent division by zero, $\\hat{m}_t$ and $\\hat{v}_t$ are bias-corrected first and second moment estimates at time step $t$.\n",
    "\n",
    "- **Loss Function**: The Binary Crossentropy loss is used for binary classification tasks. It is defined as:\n",
    "  $$\n",
    "  L = -\\frac{1}{N} \\sum_{i=1}^N [y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)]\n",
    "  $$\n",
    "  where $N$ is the number of samples, $y_i$ is the binary true label, and $p_i$ is the predicted probability of the positive class.\n",
    "\n",
    "This setup aims to optimize the binary classification problem by adjusting the model weights based on backpropagation of the error, minimizing the loss function during training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 1: 2-Layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_1(lookback, features, hu):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation='relu', return_sequences=True, name='LSTM1'))\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "    model.add(LSTM(units=hu, activation='elu', return_sequences=False, name='LSTM2'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "    \n",
    "     # Specify optimizer separately (preferred method)\n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08)\n",
    "    \n",
    "    # Model compilation \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 2: 3-Layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2(lookback, features, hu):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation='relu', return_sequences=True, name='LSTM1'))\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "    model.add(LSTM(units=hu, activation='relu', return_sequences=True, name='LSTM2'))\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "    model.add(LSTM(units=hu, activation='relu', return_sequences=False, name='LSTM3'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 3: 4-Layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_3(lookback, features, hu):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hu*2, input_shape=(lookback, features), activation='elu', return_sequences=True, name='LSTM1'))\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "    model.add(LSTM(units=hu, activation='elu', return_sequences=True, name='LSTM2'))\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "    model.add(LSTM(units=hu, activation='elu', return_sequences=True, name='LSTM3'))\n",
    "    model.add(Dropout(0.4, name='Dropout3'))\n",
    "    model.add(LSTM(units=hu, activation='elu', return_sequences=False, name='LSTM4'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 4: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_4(lookback, features, hu):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=hu*2, input_shape=(lookback, features), activation='relu', return_sequences=True, name='GRU1'))\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "    model.add(GRU(units=hu, activation='relu', return_sequences=True, name='GRU2'))\n",
    "    model.add(Dropout(0.4, name='Dropout2'))\n",
    "    model.add(GRU(units=hu, activation='relu', return_sequences=False, name='GRU3'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL 5: CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_5(lookback, features, hu):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hu, kernel_size=3, activation='relu', input_shape=(lookback, features), name='Conv1D1'))\n",
    "    model.add(MaxPooling1D(pool_size=2, name='MaxPooling1D1'))\n",
    "    model.add(LSTM(units=hu, activation='relu', name='LSTM1'))\n",
    "    model.add(Dropout(0.4, name='Dropout1'))\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001, epsilon=1e-08)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models \n",
    "models = [\n",
    "    create_model_1(lookback=seqlen, features=numfeat, hu=10),\n",
    "    create_model_2(lookback=seqlen, features=numfeat, hu=10),\n",
    "    create_model_3(lookback=seqlen, features=numfeat, hu=10),\n",
    "    create_model_4(lookback=seqlen, features=numfeat, hu=10),\n",
    "    create_model_5(lookback=seqlen, features=numfeat, hu=10)\n",
    "]\n",
    "\n",
    "# Base directory for all results\n",
    "results_path = Path('results')\n",
    "\n",
    "# Ensure the base results directory exists\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)\n",
    "\n",
    "# Create file paths directly in the results folder\n",
    "model_files = [results_path / f'model_{i+1}.h5' for i in range(5)]\n",
    "\n",
    "# Create log directories directly in the results folder\n",
    "logdirs = [os.path.join(\"./tensorboard/logs\", f'logs_{dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}_model_{i+1}') for i in range(5)]\n",
    "\n",
    "# Training loop\n",
    "for i, model in enumerate(models):\n",
    "    model_path = model_files[i].as_posix()  # files saved in results folder\n",
    "    logdir = logdirs[i]\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "        TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "    ]\n",
    "    \n",
    "    # Fit model\n",
    "    print(f'Training Model {i+1}...')\n",
    "    model.fit(\n",
    "        g_train,\n",
    "        epochs=500,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        shuffle=False,\n",
    "        class_weight=class_weight,\n",
    "        validation_data=g_val\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the model, various metrics are calculated:\n",
    "\n",
    "1. **Training and Test Accuracy**:\n",
    "\n",
    "   - **Definition**: Accuracy is the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n",
    "   \n",
    "     $$\n",
    "     \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}\n",
    "     $$\n",
    "   - **Interpretation**: While accuracy provides a quick measure of the model performance, it can be misleading, especially in datasets with class imbalance.\n",
    "    #\n",
    "2. **Confusion Matrix**:\n",
    "\n",
    "   - **Components**: The confusion matrix is a table that describes the performance of a classification model on a set of test data for which the true values are known. It includes:\n",
    "\n",
    "     - True Positives (TP): Correctly predicted positive observations.\n",
    "     - True Negatives (TN): Correctly predicted negative observations.\n",
    "     - False Positives (FP): Incorrectly predicted as positive.\n",
    "     - False Negatives (FN): Incorrectly predicted as negative.\n",
    "    \n",
    "    \n",
    "      This matrix helps in understanding the model performance across different classes, highlighting the errors in prediction.\n",
    "#\n",
    "3. **Classification Report**:\n",
    "\n",
    "   - **Metrics**:\n",
    "\n",
    "     - **Precision**: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "       $$\n",
    "       \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "       $$\n",
    "     - **Recall (Sensitivity)**: The ratio of correctly predicted positive observations to all observations in actual class.\n",
    "       $$\n",
    "       \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "       $$\n",
    "     - **F1-Score**: The weighted average of Precision and Recall.\n",
    "       $$\n",
    "       F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "       $$\n",
    "      These metrics provide a more detailed understanding of the model performance.\n",
    "#\n",
    "4. **ROC Curve and AUC Score**:\n",
    "\n",
    "   - **ROC Curve**: A graphical representation that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "\n",
    "     - **True Positive Rate (TPR)**:\n",
    "       $$\n",
    "       TPR = \\frac{TP}{TP + FN}\n",
    "       $$\n",
    "     - **False Positive Rate (FPR)**:\n",
    "       $$\n",
    "       FPR = \\frac{FP}{FP + TN}\n",
    "       $$\n",
    "   - **AUC Score**: The area under the ROC curve. It provides an aggregate measure of performance across all possible classification thresholds.\n",
    "   \n",
    "     - **Interpretation**: A higher AUC indicates better model performance, with 1 being perfect prediction and 0.5 denoting no discriminative ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Loop through each model to get predictions and accuracies\n",
    "for i, model in enumerate(models):\n",
    "    # For training accuracy\n",
    "    ytrain_pred = model.predict(g_train)\n",
    "    ytrain_pred = np.where(ytrain_pred > 0.5, 1, 0)  # Convert probabilities to class labels\n",
    "    ytrain_true = ytrain[seqlen:]  # Adjust ytrain to match the length of ytrain_pred\n",
    "    acc_train = accuracy_score(ytrain_true, ytrain_pred)\n",
    "    train_accuracies.append(acc_train)\n",
    "    \n",
    "    # For test accuracy\n",
    "    ytest_pred = np.where(model.predict(g_test, verbose=False) > 0.5, 1, 0)  # Convert probabilities to class labels\n",
    "    ytest_true = ytest[seqlen:]  # Adjust ytest to match the length of ytest_pred\n",
    "    acc_test = accuracy_score(ytest_true, ytest_pred)\n",
    "    test_accuracies.append(acc_test)\n",
    "    \n",
    "    # Print accuracies\n",
    "    print(f'Model {i+1} - Train Accuracy: {acc_train:.4f}, Test Accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of models\n",
    "num_models = 5\n",
    "\n",
    "# Loop through each model to get predictions and display confusion matrices\n",
    "fig, axes = plt.subplots(nrows=(num_models + 2) // 3, ncols=3,figsize=(8, 6))  \n",
    "axes = axes.flatten()\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    # For test accuracy\n",
    "    ytest_pred = np.where(model.predict(g_test, verbose=0) > 0.5, 1, 0).flatten()  # Convert probabilities to class labels and flatten\n",
    "    ytest_true = ytest[seqlen:]  # Adjust ytest to match the length of ytest_pred\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(ytest_true, ytest_pred)\n",
    "    \n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=axes[i], values_format='d')\n",
    "    axes[i].set_title(f'Model {i+1}')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j]) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each model to get predictions and display classification reports\n",
    "for i, model in enumerate(models):\n",
    "    # For test accuracy\n",
    "    ytest_pred = np.where(model.predict(g_test, verbose=False) > 0.5, 1, 0).flatten()  # Convert probabilities to class labels and flatten\n",
    "    ytest_true = ytest[seqlen:]  # Adjust ytest to match the length of ytest_pred\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(ytest_true, ytest_pred, target_names=['Class 0', 'Class 1'])\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f'Classification Report for Model {i+1}:\\n{report}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of models\n",
    "num_models = 5\n",
    "\n",
    "# Create subplots: 3 plots per row, and increase the figure size for larger plots\n",
    "fig, axes = plt.subplots(nrows=(num_models + 2) // 3, ncols=3,figsize=(9, 6))  \n",
    "axes = axes.flatten()\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each model to get predictions and plot ROC curves\n",
    "for i, model in enumerate(models):\n",
    "    # Generate probability predictions\n",
    "    y_proba = model.predict(g_test).flatten()\n",
    "    ytest_true = ytest[seqlen:]  # Adjust ytest to match the length of y_proba\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(ytest_true, y_proba)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    roc_auc = roc_auc_score(ytest_true, y_proba)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    axes[i].plot(fpr, tpr, color='blue', lw=2, label=f'Model {i+1} AUC = {roc_auc:.2f}')\n",
    "    axes[i].plot([0, 1], [0, 1], color='darkgray', lw=2, linestyle='--')\n",
    "    axes[i].set_xlabel('False Positive Rate')\n",
    "    axes[i].set_ylabel('True Positive Rate')\n",
    "    axes[i].set_title(f'ROC Curve for Model {i+1}')\n",
    "    axes[i].legend(loc=\"lower right\")\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies and other metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "aucs = []\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "true_negatives = []\n",
    "false_negatives = []\n",
    "\n",
    "# Loop through each model to get predictions and accuracies\n",
    "for i, model in enumerate(models):\n",
    "    # For training accuracy\n",
    "    ytrain_pred = model.predict(g_train)\n",
    "    ytrain_pred = np.where(ytrain_pred > 0.5, 1, 0)  # Convert probabilities to class labels\n",
    "    ytrain_true = ytrain[seqlen:]  # Adjust ytrain to match the length of ytrain_pred\n",
    "    acc_train = accuracy_score(ytrain_true, ytrain_pred)\n",
    "    train_accuracies.append(acc_train)\n",
    "    \n",
    "    # For test accuracy\n",
    "    ytest_pred = np.where(model.predict(g_test, verbose=False) > 0.5, 1, 0)  # Convert probabilities to class labels\n",
    "    ytest_true = ytest[seqlen:]  # Adjust ytest to match the length of ytest_pred\n",
    "    acc_test = accuracy_score(ytest_true, ytest_pred)\n",
    "    test_accuracies.append(acc_test)\n",
    "    \n",
    "    # Compute precision, recall, f1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ytest_true, ytest_pred, average='binary')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Compute AUC\n",
    "    y_proba = model.predict(g_test).flatten()\n",
    "    roc_auc = roc_auc_score(ytest_true, y_proba)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(ytest_true, ytest_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    true_negatives.append(tn)\n",
    "    false_positives.append(fp)\n",
    "    false_negatives.append(fn)\n",
    "    true_positives.append(tp)\n",
    "    \n",
    "# Create a dictionary with the results\n",
    "results_dict = {\n",
    "    'Model': [f'Model {i+1}' for i in range(len(train_accuracies))],\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1-Score': f1_scores,\n",
    "    'AUC': aucs,\n",
    "    'True Positives': true_positives,\n",
    "    'False Positives': false_positives,\n",
    "    'True Negatives': true_negatives,\n",
    "    'False Negatives': false_negatives\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(4).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the results, Model 3 was selected for its balanced performance across key metrics, particularly its strong recall and relatively high precision. While Model 2 and Model 5 achieved perfect recall, Model 3 provided a better trade-off by not only achieving high recall (0.8556) but also maintaining a reasonable precision (0.6695). This balance ensures that Model 3 makes accurate predictions while effectively managing false positives and false negatives.\n",
    "\n",
    "Model 3 higher F1-score (0.7512) compared to Model 1 and its relatively improved AUC (0.569) indicate that it generalizes better to new data, particularly in handling class imbalance. While Model 2 achieved higher recall, Model 3 offers more reliable, well-rounded predictions for the binary classification task by balancing precision and recall, making it a strong choice for the problem at hand."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the specific results path for model 2\n",
    "results = Path('results')\n",
    "\n",
    "# Define the model path within this directory\n",
    "model_path = results / 'model_3.h5'\n",
    "\n",
    "# Load the model from the specified path\n",
    "base_model = load_model(model_path)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After selecting the best model architecture, **Optuna** is used for hyperparameter optimization, with **maximizing balanced accuracy** as the objective function.\n",
    "\n",
    "**Optuna** is a framework designed for efficient hyperparameter search. It employs various algorithms to explore the hyperparameter space, with the **Tree-structured Parzen Estimator (TPE)** being the default and widely used method. TPE is a specific instance of **Bayesian optimization**, which focuses on finding the optimal hyperparameters by balancing exploration and exploitation during the search process.\n",
    "\n",
    "#### Bayesian Optimization\n",
    "\n",
    "Bayesian optimization is a sequential method for optimizing expensive, black-box functions. The core idea is to construct a probabilistic model of the objective function, often referred to as a **surrogate model**, which predicts the performance of hyperparameters. Based on this model, new hyperparameter sets are selected that are expected to yield better results.\n",
    "\n",
    "The general process of Bayesian optimization involves:\n",
    "\n",
    "1. **Surrogate Model**: The objective function $f(x)$, where $x$ represents the hyperparameters, is approximated by a surrogate model. Gaussian Processes are often used for this, though **TPE** takes a different approach.\n",
    "   \n",
    "2. **Acquisition Function**: The surrogate model is used to construct an acquisition function, such as Expected Improvement (EI), which helps select the next hyperparameters to test. The acquisition function typically balances exploration (testing new, uncertain regions) and exploitation (focusing on promising regions).\n",
    "   $$\n",
    "   \\text{EI}(x) = \\mathbb{E}[\\max(0, f(x_{\\text{best}}) - f(x))]\n",
    "   $$\n",
    "   where $f(x_{\\text{best}})$ is the best value observed so far.\n",
    "\n",
    "3. **Optimization**: The acquisition function is optimized to select the next set of hyperparameters that should be evaluated based on the surrogate model's predictions.\n",
    "\n",
    "#### Tree-structured Parzen Estimator (TPE)\n",
    "\n",
    "In TPE, rather than modeling the objective function $f(x)$ directly, it models two probability densities:\n",
    "- **$l(x)$**: The probability density of hyperparameters associated with good objective function values (higher balanced accuracy).\n",
    "- **$g(x)$**: The probability density of hyperparameters associated with worse objective function values (lower balanced accuracy).\n",
    "\n",
    "TPE selects hyperparameters by maximizing the ratio of these two densities, effectively favoring regions of the hyperparameter space that are more likely to yield good results:\n",
    "$$\n",
    "\\frac{l(x)}{g(x)}\n",
    "$$\n",
    "\n",
    "This allows TPE to efficiently explore the hyperparameter space by focusing on areas that are statistically more likely to improve the objective function.\n",
    "\n",
    "#### Objective Function\n",
    "\n",
    "The objective function for this optimization is **balanced accuracy**, which gives equal importance to the true positive rate (sensitivity) and true negative rate (specificity). It is particularly useful for handling class imbalance. Balanced accuracy is calculated as:\n",
    "$$\n",
    "\\text{Balanced Accuracy} = \\frac{1}{2} \\left( \\frac{TP}{TP + FN} + \\frac{TN}{TN + FP} \\right)\n",
    "$$\n",
    "Where:\n",
    "- $TP$ is the number of true positives,\n",
    "- $FN$ is the number of false negatives,\n",
    "- $TN$ is the number of true negatives,\n",
    "- $FP$ is the number of false positives.\n",
    "\n",
    "This metric ensures that both classes are treated fairly, which is especially important in imbalanced datasets, where standard accuracy might be misleading.\n",
    "\n",
    "#### Optimization Process \n",
    "\n",
    "The optimization process follows these steps:\n",
    "\n",
    "1. **Sampling**: Optuna samples a set of hyperparameters $x$ from the predefined search space.\n",
    "2. **Evaluation**: The model is trained with these hyperparameters, and the validation balanced accuracy is calculated.\n",
    "3. **Update**: Based on the results of this trial, Optuna updates the distributions $l(x)$ and $g(x)$.\n",
    "4. **Selection**: Optuna selects the next set of hyperparameters to test, focusing on the most promising regions of the hyperparameter space by maximizing the ratio $\\frac{l(x)}{g(x)}$.\n",
    "5. **Iteration**: This process is repeated iteratively until the stopping criterion is met (e.g., a maximum number of trials or a time limit).\n",
    "\n",
    "This iterative process aims to explore the hyperparameter space and converge on an optimal set of hyperparameters that maximize the balanced accuracy of the model. The use of **TPE** allows for efficient navigation through the hyperparameter space, focusing on areas that are more likely to improve in subsequent iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(trial):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tune the number of units in the layers\n",
    "    units1 = trial.suggest_int('units1', 4, 32, step=4)\n",
    "    units2 = trial.suggest_int('units2', 4, 32, step=4)\n",
    "    units3 = trial.suggest_int('units3', 4, 32, step=4)\n",
    "    units4 = trial.suggest_int('units4', 4, 32, step=4)\n",
    "\n",
    "    # Tune the dropout rates separately for each LSTM layer\n",
    "    dropout_rate1 = trial.suggest_float('Dropout_rate1', 0.0, 0.5, step=0.1)\n",
    "    dropout_rate2 = trial.suggest_float('Dropout_rate2', 0.0, 0.5, step=0.1)\n",
    "    dropout_rate3 = trial.suggest_float('Dropout_rate3', 0.0, 0.5, step=0.1)\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Tune activation functions\n",
    "    activation1 = trial.suggest_categorical('activation1', ['relu', 'elu'])\n",
    "    activation2 = trial.suggest_categorical('activation2', ['relu', 'elu'])\n",
    "    activation3 = trial.suggest_categorical('activation3', ['relu', 'elu'])\n",
    "    activation4 = trial.suggest_categorical('activation4', ['relu', 'elu'])\n",
    "\n",
    "    # Adding LSTM layers with individual dropout rates\n",
    "    model.add(LSTM(units=units1, input_shape=(seqlen, numfeat), activation=activation1, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate1, name='Dropout1'))\n",
    "\n",
    "    model.add(LSTM(units=units2, activation=activation2, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate2, name='Dropout2'))\n",
    "\n",
    "    model.add(LSTM(units=units3, activation=activation3, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate3, name='Dropout3'))\n",
    "\n",
    "    model.add(LSTM(units=units4, activation=activation4, return_sequences=False))\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # Specify optimizer with clipnorm\n",
    "    opt = Adam(learning_rate=learning_rate, epsilon=1e-08, decay=0.0,clipnorm=1.0)\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    tf.keras.backend.clear_session() \n",
    "\n",
    "    # Build the model with the current trial's parameters\n",
    "    model = build_model(trial)\n",
    "\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "        TensorBoard(log_dir='./tensorboard/optuna_logs')\n",
    "    ]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        g_train,\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight,  \n",
    "        validation_data=g_val,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Predict on the validation data generator \n",
    "    y_val_pred_prob = model.predict(g_val)\n",
    "    \n",
    "    # Convert probabilities to binary class labels\n",
    "    y_val_pred_classes = np.where(y_val_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "    # Extract actual labels and reshape if necessary\n",
    "    y_val_actual = np.concatenate([y for _, y in g_val], axis=0)\n",
    "\n",
    "    # Calculate Balanced Accuracy\n",
    "    balanced_acc = balanced_accuracy_score(y_val_actual, y_val_pred_classes)\n",
    "\n",
    "    # Return the balanced accuracy for optimization\n",
    "    return balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study = optuna.create_study(direction='maximize', study_name=\"optuna_lstm\")\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the study\n",
    "best_params = study.best_trial.params \n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameter values:\", best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Optimization History plot is a visual representation of the performance of different trials over the course of the  optimization process. \n",
    "\n",
    "This plot can be useful useful for diagnosing the progress, identifying potential issues, and understanding the overall behavior of the optimizer during the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the optimization history plot\n",
    "fig = vis.plot_optimization_history(study)\n",
    "\n",
    "# Adjust the figure size\n",
    "fig.update_layout(width=650,height=450)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Parameter Importance plot provides insights into the relative impact of each hyperparameter on the objective value during the optimization. \n",
    "\n",
    "This plot is valuable for gaining a deeper understanding of the process and for making informed decisions about which hyperparameters to prioritize in future experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the parameter importance plot\n",
    "fig = vis.plot_param_importances(study)\n",
    "\n",
    "# Adjust the figure size\n",
    "fig.update_layout(width=650,height=450)\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Parallel Coordinate plot is a visualization that allows us to explore the relationships and the objective value across different trials.\n",
    "\n",
    "##### Interpretation:\n",
    "\n",
    "- **Identifying Relationships**: The plot helps identify how different hyperparameters work together to affect the objective value. For example, we can see if a particular range of values for one hyperparameter consistently leads to better performance when combined with specific values of another hyperparameter.\n",
    "\n",
    "- **Visualizing Trade-offs**: The parallel coordinate plot allows us to visualize trade-offs between different hyperparameters. We can observe how changing one might require adjustments in another to maintain optimal performance.\n",
    "\n",
    "- **Exploring High-Performing Regions**: By focusing on lines that correspond to the best objective values, we can identify combinations of hyperparameters that consistently lead to good performance, guiding further optimization efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the parallel coordinate plot\n",
    "fig = vis.plot_parallel_coordinate(study)\n",
    "\n",
    "# Adjust the figure size\n",
    "fig.update_layout(width=650,height=450)\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes the tested configurations and their corresponding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the study\n",
    "data = []\n",
    "for trial in study.trials:\n",
    "    trial_data = {\n",
    "        'number': trial.number,\n",
    "        'value': trial.value,\n",
    "        **trial.params  # Unpacking the parameters dictionary into the DataFrame\n",
    "    }\n",
    "    data.append(trial_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "trials_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "trials_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./tensorboard/optuna_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_best_model(best_params):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Use the best hyperparameters found\n",
    "    units1 = best_params['units1']\n",
    "    units2 = best_params['units2']\n",
    "    units3 = best_params['units3']\n",
    "    units4 = best_params['units4']\n",
    "    dropout_rate1 = best_params['Dropout_rate1']\n",
    "    dropout_rate2 = best_params['Dropout_rate2']\n",
    "    dropout_rate3 = best_params['Dropout_rate3']\n",
    "    learning_rate = best_params['learning_rate']\n",
    "    activation1 = best_params['activation1']\n",
    "    activation2 = best_params['activation2']\n",
    "    activation3 = best_params['activation3']\n",
    "    activation4 = best_params['activation4']\n",
    "\n",
    "    # Adding the first LSTM layer\n",
    "    model.add(LSTM(units=units1, input_shape=(seqlen, numfeat), activation=activation1, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate1, name='Dropout1'))\n",
    "\n",
    "    # Adding the second LSTM layer\n",
    "    model.add(LSTM(units=units2, activation=activation2, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate2, name='Dropout2'))\n",
    "\n",
    "    # Adding the third LSTM layer\n",
    "    model.add(LSTM(units=units3, activation=activation3, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate3, name='Dropout3'))\n",
    "\n",
    "    # Adding the fourth LSTM layer \n",
    "    model.add(LSTM(units=units4, activation=activation4, return_sequences=False))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', name='Output'))\n",
    "\n",
    "    # Specify optimizer\n",
    "    opt = Adam(learning_rate=learning_rate, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=BinaryCrossentropy(), \n",
    "                  metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define log directory\n",
    "logdir = os.path.join(\"./tensorboard/logs\", dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '_tuned_model')\n",
    "\n",
    "# Define the model path within this directory\n",
    "best_model_path = (results_path / 'tuned_model.h5').as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the best model\n",
    "best_model = build_best_model(best_params)\n",
    "\n",
    "# Train the best model\n",
    "callback_best = [EarlyStopping(patience=5, monitor='loss', mode='min', verbose=1, restore_best_weights=True),\n",
    "                 ModelCheckpoint(filepath=best_model_path, verbose=1, monitor='loss', save_best_only=True),\n",
    "                 TensorBoard(log_dir=logdir, histogram_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(g_train, \n",
    "               epochs=50, \n",
    "               validation_data=g_val, \n",
    "               callbacks=callback_best, \n",
    "               class_weight=class_weight, \n",
    "               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "ytest_pred_prob = best_model.predict(g_test)\n",
    "ytest_pred = np.where(ytest_pred_prob > 0.5, 1, 0)\n",
    "ytest_pred[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the training set\n",
    "ytrain_pred_prob = best_model.predict(g_train)\n",
    "ytrain_pred = np.where(ytrain_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracies\n",
    "acc_train = accuracy_score(ytrain_true, ytrain_pred)\n",
    "acc_test = accuracy_score(ytest_true, ytest_pred)\n",
    "\n",
    "print(f'Train Accuracy: {acc_train:.4f}, Test Accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for test data\n",
    "cm = confusion_matrix(ytest_true, ytest_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(3, 3)) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.grid(False)  # Turn off the grid \n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(ytest_true, ytest_pred, target_names=['Class 0', 'Class 1'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and AUC for test data\n",
    "fpr, tpr, thresholds = roc_curve(ytest_true, ytest_pred_prob)\n",
    "roc_auc = roc_auc_score(ytest_true, ytest_pred_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(5, 4)) \n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='darkgray', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies and other metrics for both models\n",
    "model_names = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "aucs = []\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "true_negatives = []\n",
    "false_negatives = []\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Base Model': base_model,\n",
    "    'Tuned Model': best_model\n",
    "}\n",
    "\n",
    "# Loop through each model to get predictions and accuracies\n",
    "for model_name, model in models.items():\n",
    "    model_names.append(model_name)\n",
    "    \n",
    "    # For training accuracy\n",
    "    ytrain_pred = model.predict(g_train)\n",
    "    ytrain_pred = np.where(ytrain_pred > 0.5, 1, 0)  # Convert probabilities to class labels\n",
    "    ytrain_true = ytrain[seqlen:]  # Adjust ytrain to match the length of ytrain_pred\n",
    "    acc_train = accuracy_score(ytrain_true, ytrain_pred)\n",
    "    train_accuracies.append(acc_train)\n",
    "    \n",
    "    # For test accuracy\n",
    "    ytest_pred = np.where(model.predict(g_test, verbose=False) > 0.5, 1, 0)  # Convert probabilities to class labels\n",
    "    ytest_true = ytest[seqlen:]  # Adjust ytest to match the length of ytest_pred\n",
    "    acc_test = accuracy_score(ytest_true, ytest_pred)\n",
    "    test_accuracies.append(acc_test)\n",
    "    \n",
    "    # Compute precision, recall, f1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ytest_true, ytest_pred, average='binary')\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Compute AUC\n",
    "    y_proba = model.predict(g_test).flatten()\n",
    "    roc_auc = roc_auc_score(ytest_true, y_proba)\n",
    "    aucs.append(roc_auc)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(ytest_true, ytest_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    true_negatives.append(tn)\n",
    "    false_positives.append(fp)\n",
    "    false_negatives.append(fn)\n",
    "    true_positives.append(tp)\n",
    "    \n",
    "# Create a dictionary with the results\n",
    "results_dict = {\n",
    "    'Model': model_names,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Test Accuracy': test_accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1-Score': f1_scores,\n",
    "    'AUC': aucs,\n",
    "    'True Positives': true_positives,\n",
    "    'False Positives': false_positives,\n",
    "    'True Negatives': true_negatives,\n",
    "    'False Negatives': false_negatives\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(4).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison between the base and tuned models highlights a shift in performance focus after tuning. The tuned model achieved higher precision, which reduced the number of false positives and improved its ability to make more accurate positive predictions. However, this gain in precision came with a reduction in recall, meaning the tuned model missed more actual positive cases than the base model. As a result, the F1-score, which balances precision and recall, was lower for the tuned model. Although the overall accuracy and AUC remained relatively similar, the tuned model favored precision over recall, making it more conservative in predicting positive outcomes. This trade-off illustrates the model shift towards avoiding false positives at the expense of identifying all positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model path within this directory\n",
    "tuned_model_path = results_path / 'tuned_model.h5'\n",
    "\n",
    "# Load the model from the specified path\n",
    "tuned_model = load_model(tuned_model_path)\n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Strategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trading strategy is based on applying the model predictions to generate trading signals (***`1`*** and ***`0`***, representing ***`long position`*** and ***`do nothing/stay out of the market`***, respectively). These signals are then used to create a strategy by multiplying the returns by the signals, adjusted for sequence length. Key metrics are also computed to evaluate the effectivenes of the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the predictions with the test data in df\n",
    "df_test = df.iloc[-len(Xtest):]  # Adjust based on the length of test set\n",
    "df_test = df_test.iloc[seqlen:]  # Further adjust for the sequence length\n",
    "df_test['Signal'] = ytest_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Signal'].dropna(inplace=True)\n",
    "df_test['Strategy'] = df_test['Return'] * df_test['Signal'].shift(1).fillna(0) \n",
    "df_test.dropna(subset=['Strategy', 'Return'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localize index for pyfolio\n",
    "df_test.index = df_test.index.tz_localize('utc')\n",
    "pf.create_returns_tear_sheet(df_test['Strategy'],benchmark_rets=df_test['Return'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Financial Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Maximum Drawdown\n",
    "def max_drawdown(return_series):\n",
    "    cum_returns = (1 + return_series).cumprod()\n",
    "    peak = cum_returns.expanding(min_periods=1).max()\n",
    "    drawdown = ((cum_returns / peak) - 1) * 100\n",
    "    return drawdown.min()\n",
    "\n",
    "# Calculate Total Return\n",
    "cumulative_return_strategy = ((df_test['Strategy'] + 1).prod() - 1) * 100 \n",
    "cumulative_return = ((df_test['Return'] + 1).prod() - 1) * 100\n",
    "\n",
    "# Calculate Annualized Sharpe Ratio (Assuming risk-free rate = 0 and 365 trading days for Bitcoin)\n",
    "annualized_sharpe_ratio_strategy = (df_test['Strategy'].mean() / df_test['Strategy'].std()) * np.sqrt(365)\n",
    "annualized_sharpe_ratio_return = (df_test['Return'].mean() / df_test['Return'].std()) * np.sqrt(365)\n",
    "\n",
    "# Calculate Maximum Drawdown\n",
    "max_drawdown_strategy = max_drawdown(df_test['Strategy'])\n",
    "max_drawdown_return = max_drawdown(df_test['Return'])\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "metrics = pd.DataFrame({\n",
    "    'Metric': ['Cumulative Return %', 'Sharpe Ratio', 'Max Drawdown %'],\n",
    "    'Strategy': [cumulative_return_strategy, annualized_sharpe_ratio_strategy, max_drawdown_strategy],\n",
    "    'Benchmark': [cumulative_return, annualized_sharpe_ratio_return, max_drawdown_return]\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "metrics.round(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a summary of the steps taken throughout this project, highlighting the key techniques and methods applied at each stage, along with their specific roles in the analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Step                         | Technique                              | Description                                                                                                                                                  |\n",
    "|------------------------------|----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 1. Data Collection            | Yahoo Finance API                      | Gathering historical Bitcoin prices from Yahoo Finance.                                                                                                       |\n",
    "| 2. Data Cleaning/Preparation  | DayTransformer                         | Custom transformer for preprocessing dates and engineering features related to the days of the week.                                                          |\n",
    "|                               | RobustScaler                           | Standardizing feature values to handle outliers and ensure consistent model performance.                                                                      |\n",
    "|                               | Class Imbalance Handling               | Computing class weights to address class imbalance in the dataset.                                                                                            |\n",
    "|                               | Train-Test Split                       | Splitting the dataset into training, validation, and testing subsets to evaluate model performance.                                                           |\n",
    "|                               | Label Definition                       | Creating the `dir` column to indicate trading signals (binary classification).                                                                                |\n",
    "|                               | Pandas TA                              | Technical analysis library for generating a wide range of technical indicators for trading data.                                                              |\n",
    "| 3. Exploratory Data Analysis  | Sweetviz                               | Generating an exploratory data analysis report to find patterns and relationships in the data.                                                                 |\n",
    "|                               | Box Plots                              | Visualizing the distribution of data and identifying outliers in features.                                                                                    |\n",
    "|                               | Scatter Plots                          | Analyzing relationships and correlations between pairs of features.                                                                                           |\n",
    "| 4. Feature Engineering        | Boruta                                 | An ensemble-based method for robust feature selection in high-dimensional datasets.                                                                           |\n",
    "|                               | Correlation Analysis                   | Identifying and removing highly correlated features to handle multicollinearity.                                                                              |\n",
    "|                               | Mutual Information                     | Quantifying dependencies between variables to select the most relevant features for the model.                                                                |\n",
    "|                               | K-means Clustering                     | Grouping similar patterns in the data and refining features by reducing dimensionality. Clarifies patterns in the data.                                        |\n",
    "| 5. Model Building and Training| LSTM Network Architecture              | Applying LSTM to model time-series data and capture temporal dependencies.                                                                                    |\n",
    "|                               | GRU Network Architecture               | Implementing GRU models to capture temporal patterns with a more simplified architecture compared to LSTMs.                                                    |\n",
    "|                               | Hybrid Models                          | Combining LSTM and convolutional layers to leverage both spatial and temporal dependencies in the data.                                                       |\n",
    "|                               | TimeseriesGenerator                    | Structuring the data for all models in time-series forecasting.                                                                                               |\n",
    "| 6. Hyperparameter Tuning      | Optuna                                 | Systematically optimizing hyperparameters using Bayesian optimization techniques to enhance model performance.                                                 |\n",
    "|                               | TensorBoard                            | Monitoring hyperparameter tuning process and visualizing performance metrics.                                                                                 |\n",
    "| 7. Model Evaluation           | Evaluation Metrics                     | Using accuracy, precision, recall, F1-score, and AUC to assess model performance.                                                                             |\n",
    "|                               | Confusion Matrix                       | Analyzing the model classification performance by examining true positives, false positives, true negatives, and false negatives.                             |\n",
    "|                               | ROC Curve and AUC Score                | Graphically representing the diagnostic ability of the binary classifier and calculating the area under the curve.                                             |\n",
    "|                               | Backtesting                            | Evaluating the trading strategy using Pyfolio and calculating financial metrics.                                                                              |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is divided into several key stages: data collection and pre-processing, feature engineering, and the development of a Bitcoin price prediction model using deep learning architectures. We gathered 8 years of Bitcoin market data from Yahoo Finance, ensuring that the dataset was properly structured and cleaned to meet the demands of time-series forecasting.\n",
    "\n",
    "During the feature engineering phase, a variety of technical indicators were incorporated, and advanced selection techniques such as Boruta, correlation analysis, mutual information, and K-means clustering were employed to refine the feature set. The use of the RobustScaler for data normalization helped mitigate the impact of outliers, which is critical for maintaining consistent model performance.\n",
    "\n",
    "Multiple models, including LSTM, GRU, and hybrid architectures with convolutional layers, were evaluated for their effectiveness in capturing the temporal dependencies of Bitcoin prices. A 4-Layer LSTM model was chosen for its ability to retain long-term memory in sequential data, making them particularly suited to the volatile Bitcoin market. The model was further optimized using Optuna, which systematically explored the hyperparameter space to enhance performance, while TensorBoard enabled real-time monitoring and tracking during training and tuning.\n",
    "\n",
    "Through backtesting, we validated the performance of the model against historical data, assessing its potential in a real-world trading environment. Despite the improvements made through feature engineering and hyperparameter tuning, the inherent volatility of the Bitcoin market presents significant challenges for maintaining predictive accuracy. Model performance was impacted by sharp price movements and periods of unpredictable behavior, which reflects the difficulty of forecasting in such a dynamic market.\n",
    "\n",
    "Furthermore, while the model demonstrated the ability to predict trends with reasonable accuracy, several practical limitations were acknowledged. These include the potential effects of trading costs, slippage, and the latency of real-time data processing, all of which can affect the model practical effectiveness. The complexity of LSTM models also led to longer training times and increased computational demands. The importance of managing the bias-variance tradeoff cannot be overstated, and further improvements are necessary to ensure the model generalizes effectively to unseen data.\n",
    "\n",
    "Looking ahead, there are several avenues for further development:\n",
    "- **Enhanced Feature Engineering**: Future work can explore advanced techniques such as genetic algorithms, sentiment analysis from social media, and blockchain-specific metrics to enrich the feature set.\n",
    "#\n",
    "- **Alternative Models**: Investigating other deep learning architectures, such as Transformers or Deep Reinforcement Learning, could provide improvements in capturing complex patterns.\n",
    "#\n",
    "- **Real-Time Adaptation**: Developing methods for real-time data processing and model adaptation can enhance the model responsiveness to market changes, improving its practical utility.\n",
    "#\n",
    "- **Advanced Hyperparameter Tuning**: Exploring more sophisticated hyperparameter optimization techniques and increasing the search space could further enhance model performance.\n",
    "#\n",
    "- **Robust Backtesting**: Continuous backtesting under various market conditions and stress-testing the model against historical market crashes or bull runs will provide deeper insights into its robustness and reliability.\n",
    "#\n",
    "- **Integration with Automated Trading Systems**: Implementing the model in a real-world automated trading system, with considerations for latency, execution speed, and integration with trading platforms.\n",
    "#\n",
    "- **Risk Management Strategies**: Incorporating advanced risk management techniques, such as dynamic position sizing and stop-loss mechanisms, can help mitigate potential losses and enhance the overall strategy performance.\n",
    "\n",
    "In summary, while the model demonstrates potential in predicting Bitcoin price movements and informing trading strategies, continuous refinement and adaptation are crucial to maintaining its relevance and effectiveness in the rapidly evolving cryptocurrency market. Ongoing research and development, combined with rigorous backtesting and real-world application, will be key to unlocking its full potential."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. CQF Elective Workshop Advanced Machine Learning I.\n",
    "\n",
    "2. [Keras API](https://keras.io)\n",
    "\n",
    "3. [TensorFlow API](https://www.tensorflow.org)\n",
    "\n",
    "4. [Optuna API](https://optuna.readthedocs.io/en/stable/)\n",
    "\n",
    "5. Kimoto, T., Asakawa, K., Yoda, M., & Takeoka, M. (1990). Stock market prediction system with modular neural networks. \n",
    "\n",
    "6. Kim, K.-J. (2003). Financial time series forecasting using support vector machines. \n",
    "   - URL: [10.1016/S0925-2312(03)00372-2](https://doi.org/10.1016/S0925-2312(03)00372-2)\n",
    "\n",
    "7. Chong, E., Han, C., & Park, F. C. (2017). Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies. \n",
    "   - URL: [10.1016/j.eswa.2017.04.030](https://doi.org/10.1016/j.eswa.2017.04.030)\n",
    "\n",
    "8. Fischer, T., & Krauss, C. (2018). Deep learning with long short-term memory networks for financial market predictions. \n",
    "   - URL: [10.1016/j.ejor.2017.11.054](https://doi.org/10.1016/j.ejor.2017.11.054)\n",
    "\n",
    "9. McNally, S., Roche, J., & Caton, S. (2018). Predicting the price of Bitcoin using machine learning. \n",
    "   - URL: [10.1109/PDP2018.2018.00060](https://doi.org/10.1109/PDP2018.2018.00060)\n",
    "\n",
    "10. Borovykh, A., Bohte, S., & Oosterlee, C. W. (2017). Conditional time series forecasting with convolutional neural networks. \n",
    "    - URL: [https://arxiv.org/abs/1703.04691](https://arxiv.org/abs/1703.04691)\n",
    "\n",
    "11. Wang, J., Liu, J., & She, H. (2020). A hybrid model combining CNN and LSTM for stock market prediction.\n",
    "\n",
    "12. Bergstra, J., Bardenet, R., Bengio, Y., & Kgl, B. (2011). Algorithms for Hyper-Parameter Optimization. \n",
    "- URL: https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\n",
    "\n",
    "13. Kursa, M. B., & Rudnicki, W. R. (2010). Feature Selection with the Boruta Package. \n",
    "    - URL: [https://www.jstatsoft.org/article/view/v036i11](https://www.jstatsoft.org/article/view/v036i11)\n",
    "\n",
    "14. Benesty, J., Chen, J., Huang, Y., & Cohen, I. (2009). Pearson Correlation Coefficient. Springer.\n",
    "\n",
    "15. Cover, T. M., & Thomas, J. A. (2006). Elements of Information Theory. John Wiley & Sons.\n",
    "\n",
    "16. MacQueen, J. (1967). Some Methods for classification and Analysis of Multivariate Observations. \n",
    "    - URL: [https://projecteuclid.org/euclid.bsmsp/1200512992](https://projecteuclid.org/euclid.bsmsp/1200512992)\n",
    "    \n",
    "17. Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical Bayesian optimization of machine learning algorithms.\n",
    "    - URL: [https://arxiv.org/abs/1206.2944](https://arxiv.org/abs/1206.2944)\n",
    "    \n",
    "18. Explaining Hyperparameter Optimization via Partial Dependence Plots. (2021). arXiv preprint.\n",
    "    - URL: [https://arxiv.org/abs/2111.04820](https://arxiv.org/abs/2111.04820)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f9f36b9083d899d49c4aa8107152e17fde22bc75b9c0b9282fc4c8f07875032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
